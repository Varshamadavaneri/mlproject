# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uU41fW7FKsq6CGSZiDBFDs6eCGCZ8v0R
"""

from google.colab import files

# Upload the ZIP file or individual CSVs
uploaded = files.upload()  # Select files from your computer

import pandas as pd

# Load the CVE dataset
cve_df = pd.read_csv('cve.csv')

# Display first 5 rows to inspect structure
print(cve_df.head())

# Show column names and data types
print(cve_df.info())

# Check for missing values
print(cve_df.isnull().sum())

import pandas as pd

# Load the dataset
cve_df = pd.read_csv('cve.csv')

# 1. Show original structure
print("Original columns:", cve_df.columns.tolist())
print("\nFirst 2 rows:")
print(cve_df.head(2))

# 2. Rename columns to more intuitive names (optional but recommended)
column_mapping = {
    'summary': 'description',
    'cvss': 'cvss_score',
    'pub_date': 'published_date',
    'cwe_name': 'vulnerability_type'
}
cve_df = cve_df.rename(columns=column_mapping)

# 3. Handle Missing Values
print("\nMissing values before cleaning:")
print(cve_df[['description', 'cvss_score']].isnull().sum())

# Drop rows where critical fields are missing
cve_df = cve_df.dropna(subset=['description', 'cvss_score'])

# 4. Feature Selection
selected_columns = ['Unnamed: 0', 'description', 'cvss_score', 'published_date', 'vulnerability_type']
cve_df = cve_df[selected_columns]

# 5. Convert CVSS scores to severity levels
def categorize_severity(score):
    try:
        score = float(score)
        if score >= 9.0: return 'Critical'
        elif score >= 7.0: return 'High'
        elif score >= 4.0: return 'Medium'
        else: return 'Low'
    except:
        return 'Unknown'

cve_df['severity'] = cve_df['cvss_score'].apply(categorize_severity)

# 6. Final Data Check
print("\nMissing values after cleaning:")
print(cve_df.isnull().sum())

print("\nData types:")
print(cve_df.dtypes)

print("\nSeverity distribution:")
print(cve_df['severity'].value_counts())

# 7. Save Cleaned Data
cve_df.to_csv('cleaned_cve.csv', index=False)
print("\nSaved cleaned data to 'cleaned_cve.csv'")

import pandas as pd

df = pd.read_csv('cleaned_cve.csv')
print(df.head())

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

# Features and Labels
X = df['description']
y = df['severity']

# Encode labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# Vectorize text
vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# Train model
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train_vec, y_train)

# Predict
y_pred = clf.predict(X_test_vec)

# Evaluate
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

import joblib

joblib.dump(clf, 'severity_classifier.pkl')
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')
joblib.dump(label_encoder, 'label_encoder.pkl')

